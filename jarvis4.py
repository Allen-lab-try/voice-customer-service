import sounddevice as sd
import numpy as np
import edge_tts
import pvporcupine
import pyaudio
import asyncio
import struct
import os
import time
import subprocess  # â¬… ç”¨æ–¼é—œé–‰æ’­æ”¾å™¨
import whisperx  # âœ… WhisperX æ›¿ä»£ Whisper
from llama_cpp import Llama  # âœ… ä½¿ç”¨æœ¬åœ° LLaMA æ›¿ä»£ OpenAI API
import torch
from collections import deque  # ğŸš€ ç”¨ä¾†å­˜æ­·å²å°è©±è¨˜éŒ„


# **ğŸ”¹ åŠ è¼‰ LLaMA 2 æˆ– Mistral 7B æ¨¡å‹**
MODEL_PATH = r"D:\model\mistral-7b-instruct-v0.1.Q4_K_M.gguf"  # è«‹ç¢ºèªæ¨¡å‹è·¯å¾‘æ­£ç¢º

# âœ… å•Ÿç”¨ GPU åŠ é€Ÿï¼Œæ¸›å°‘ LLaMA ç”Ÿæˆæ™‚é–“
llm = Llama(
    model_path=MODEL_PATH, 
    n_ctx=2048,  
    n_batch=512,  # ğŸš€ æé«˜æ‰¹é‡è™•ç†å¤§å°ï¼ŒåŠ é€Ÿæ¨ç†
    n_gpu_layers=40  # ğŸš€ è®“å‰ 20 å±¤é‹è¡Œåœ¨ GPU ä¸Šï¼ˆå¦‚æœæœ‰ GPUï¼‰
)


# **ğŸ”¹ åŠ è¼‰ WhisperX æ¨¡å‹**
device = "cuda" if torch.cuda.is_available() else "cpu"  # âœ… è‡ªå‹•é¸æ“‡ GPU æˆ– CPU
whisperx_model = whisperx.load_model("medium", device)

buffer = []
MAX_BUFFER_SIZE = 16000 * 6  # é™åˆ¶æœ€å¤§ç·©è¡å€ç‚º 5 ç§’
ACCESS_KEY = "w7yAkwffkJG/Odyqljlz/KZItUsA5YRioFz2vVB7F7rAxCfu4XkYxw=="  # é€™è£¡å¡«å…¥ä½ çš„ Porcupine API Key

is_speaking = False  # **ç”¨ä¾†æ¨™è¨˜ TTS æ’­æ”¾æ™‚æ˜¯å¦æ‡‰è©²éœéŸ³éŒ„éŸ³**
player_process = None  # **ç”¨ä¾†å­˜å„²æ’­æ”¾ç¨‹å¼çš„é€²ç¨‹**
awaiting_wake_word = True  # **æ§åˆ¶æ˜¯å¦è¦é€²è¡Œè½‰éŒ„èˆ‡å°ç­”**

# âœ… **åŠ å…¥å°è©±æ­·å²**
conversation_history = deque(maxlen=5)  # ğŸš€ åªä¿å­˜æœ€è¿‘ 5 å¥å°è©±

# **ğŸ”¹ 1. LLaMA è§£æèªæ„ä¸¦ç”Ÿæˆå›æ‡‰**
def llama_response(user_text):
    """ ä½¿ç”¨æœ¬åœ° LLaMA ä¾†ç”Ÿæˆå›æ‡‰ """
    response = llm(
        f"ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„èªéŸ³å®¢æœåŠ©ç†ï¼Œè«‹æä¾›ç²¾æº–çš„å›æ‡‰ã€‚\nä½¿ç”¨è€…ï¼š{user_text}\nåŠ©æ‰‹ï¼š",
        max_tokens=256,
        stop=["\n", "ä½¿ç”¨è€…ï¼š"],  # é¿å…ç„¡é™ç”Ÿæˆ
        echo=False
    )
    return response["choices"][0]["text"].strip()

# **ğŸ”¹ 2. èªéŸ³åˆæˆï¼ˆEdge TTSï¼‰**
async def text_to_speech(text):
    """ ä½¿ç”¨ Edge TTS è½‰èªéŸ³ä¸¦æ’­æ”¾ï¼Œç¢ºä¿éŒ„éŸ³æš«åœï¼Œæ’­æ”¾çµæŸå¾Œè‡ªå‹•é—œé–‰ """
    global is_speaking, player_process
    is_speaking = True  # **æ¨™è¨˜ç‚º TTS æ’­æ”¾ä¸­ï¼Œé˜²æ­¢éŒ„éŸ³**
    
    try:
        filename = "response.mp3"
        
        # **æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼Œé¿å…è¦†è“‹å•é¡Œ**
        if os.path.exists(filename):
            os.remove(filename)

        tts = edge_tts.Communicate(text, voice="zh-CN-XiaoxiaoNeural")
        await tts.save(filename)

        # **æ’­æ”¾éŸ³è¨Š**
        if os.name == "nt":  # Windows
            player_process = subprocess.Popen(["start", filename], shell=True)  # é–‹å•Ÿæ’­æ”¾å™¨
        elif os.name == "posix":  # macOS/Linux
            if "darwin" in os.sys.platform:
                player_process = subprocess.Popen(["afplay", filename])  # macOS
            else:
                player_process = subprocess.Popen(["mpg123", filename])  # Linux

        # **ç­‰å¾…æ’­æ”¾å™¨çµæŸ**
        player_process.wait()

        # **é—œé–‰æ’­æ”¾å™¨**
        stop_audio_playback()

    except Exception as e:
        print(f"èªéŸ³è½‰æ›éŒ¯èª¤: {e}")

    is_speaking = False  # **æ’­æ”¾çµæŸï¼Œæ¢å¾©éŒ„éŸ³**
    global awaiting_wake_word
    awaiting_wake_word = True  # **å›åˆ°ç­‰å¾…å–šé†’è©ç‹€æ…‹**

def stop_audio_playback():
    """ å¼·åˆ¶é—œé–‰æ’­æ”¾ç¨‹å¼ï¼Œç¢ºä¿æ’­æ”¾å®Œç•¢å¾Œä¸å½±éŸ¿éŒ„éŸ³ """
    global player_process
    if player_process is not None:
        try:
            if os.name == "nt":  # Windows
                subprocess.run("taskkill /F /IM wmplayer.exe", shell=True)  # é—œé–‰ Windows Media Player
            elif os.name == "posix":
                subprocess.run("pkill afplay", shell=True)  # macOS
                subprocess.run("pkill mpg123", shell=True)  # Linux
        except Exception as e:
            print(f"é—œé–‰æ’­æ”¾å™¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

# **ğŸ”¹ 3. èªéŸ³è™•ç† `process_audio()`**
def process_audio(indata, frames, callback_time, status):
    global buffer, is_speaking, awaiting_wake_word

    if status:
        print(f"ç‹€æ…‹éŒ¯èª¤ï¼š{status}")

    # **TTS æ’­æ”¾æ™‚ä¸éŒ„éŸ³**
    if is_speaking:
        return

    # è½‰æ›æ•¸æ“šæ ¼å¼
    audio_data = np.array(indata[:, 0], dtype=np.float32)
    buffer.extend(audio_data)

    print(f"ğŸ¤ ç›®å‰éŒ„éŸ³ä¸­ï¼ŒBuffer é•·åº¦: {len(buffer)}")

    # é™åˆ¶ `buffer` å¤§å°
    if len(buffer) > MAX_BUFFER_SIZE:
        print("ğŸ”¹ åµæ¸¬åˆ°å®Œæ•´èªå¥ï¼Œé–‹å§‹è½‰éŒ„...")

        # **ç¢ºä¿ buffer è½‰æ›ç‚ºæ­£ç¢ºæ ¼å¼**
        audio_input = np.array(buffer, dtype=np.float32)

        # **ä½¿ç”¨ WhisperX é€²è¡Œè½‰éŒ„**
        result = whisperx_model.transcribe(audio_input, batch_size=32, language="zh")

        recognized_text = " ".join([segment["text"] for segment in result["segments"]])

        print(f"ğŸ—£ WhisperX è½‰éŒ„ï¼š{recognized_text}")

        # **æ¸…ç©º bufferï¼Œé˜²æ­¢é‡è¤‡è½‰éŒ„**
        buffer.clear()

        # **æª¢æŸ¥å–šé†’è© "jarvis" æ˜¯å¦è¢«æåŠ**
        if "jarvis" not in recognized_text.lower():
            print("âŒ æœªåµæ¸¬åˆ°å–šé†’è© 'jarvis'ï¼Œä¸è§¸ç™¼å›æ‡‰ã€‚")
            return
        
        print(f"ğŸ—£ï¸ è½‰éŒ„çµæœï¼š{recognized_text}")
        response_text = llama_response(recognized_text)  
        print(f"ğŸ¤– LLaMA å›æ‡‰ï¼š{response_text}")
        awaiting_wake_word = False  # **ç­‰å¾…å°è©±å®Œæˆå¾Œå†åµæ¸¬æ–°çš„å–šé†’è©**
        asyncio.run(text_to_speech(response_text))

# **ğŸ”¹ 4. ä¸¦è¡Œè™•ç† LLaMA å’Œ TTS**
async def process_and_respond(user_text):
    """ âœ… LLaMA ç”Ÿæˆ & Edge TTS èªéŸ³åˆæˆåŒæ™‚é€²è¡Œ """
    response_task = asyncio.create_task(llama_response(user_text))  # **LLaMA ç”Ÿæˆ**
    response_text = await response_task  

    print(f"ğŸ¤– LLaMA å›æ‡‰ï¼š{response_text}")

    # âœ… **èªéŸ³åˆæˆåŒæ™‚åŸ·è¡Œ**
    speech_task = asyncio.create_task(text_to_speech(response_text))
    
    await speech_task

# **ğŸ”¹ 5. é–‹å§‹ç›£è½**
def start_conversation():
    print("ğŸ¤ ç­‰å¾…å–šé†’è© 'jarvis'...")
    try:
        with sd.InputStream(callback=process_audio, channels=1, samplerate=16000, blocksize=2048):
            while True:
                sd.sleep(50)  # **æ¸›å°‘ CPU éåº¦ä½¿ç”¨**
    except KeyboardInterrupt:
        print("\nğŸ›‘ åµæ¸¬åˆ° Ctrl+Cï¼Œå®‰å…¨é€€å‡ºç¨‹å¼ã€‚")

# **ğŸ”¹ 5. å•Ÿå‹•ç¨‹å¼**
if __name__ == "__main__":
    start_conversation()